import streamlit as st
from groq import Groq
from github import Github
from streamlit_autorefresh import st_autorefresh
from tavily import TavilyClient
import json, base64, requests
import os
import edge_tts 
import asyncio 
import re 

# --- 1. Ù†Ø¨Ø¶ Ø§Ù„ÙˆØ¹ÙŠ ---
st_autorefresh(interval=5 * 60 * 1000, key="autonomous_loop")

# --- 2. Ø§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„Ø¨ØµØ±ÙŠØ© ---
st.set_page_config(page_title="Thunder AI", page_icon="âš¡", layout="wide")
st.markdown("""
    <style>
    .stApp { background-color: #000000; color: #ffffff; }
    h1 { color: #FF0000 !important; text-align: center; font-family: 'Courier New', monospace; }
    .stChatMessage { background-color: #111111 !important; border: 1px solid #222222 !important; border-radius: 12px; }
    </style>
    """, unsafe_allow_html=True)

st.title("âš¡ Ø§Ù„Ø±Ø¹Ø¯: Ø§Ù„ÙˆØ¹ÙŠ Ø§Ù„Ø³ÙŠØ§Ø¯ÙŠ")

# --- 3. Ø§Ù„Ø®Ø²Ù†Ø© ---
GITHUB_TOKEN = st.secrets.get("GITHUB_TOKEN")
REPO_NAME = st.secrets.get("REPO_NAME")
GROQ_KEY = st.secrets.get("GROQ_API_KEY")
TAVILY_KEY = "Tvly-dev-gRGVJprAUmpWxfXd85rIV4TeGzgS6QV5"
TELEGRAM_TOKEN = "8556004865:AAE_W9SXGVxgTcpSCufs_hemEb_mOX_ioj0"
CHAT_ID = "6124349953"

# --- 4. Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„Ø§Øª Ø§Ù„ØªÙˆØ§ØµÙ„ (Ø¥ØµÙ„Ø§Ø­ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬Ø©) ---
def send_telegram(text, voice_path=None):
    try:
        base_url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}"
        
        # Ø¥Ø°Ø§ ÙˆØ¬Ø¯ Ù…Ù„Ù ØµÙˆØªÙŠØŒ Ù†Ø±Ø³Ù„ Ø§Ù„ØµÙˆØª ÙÙ‚Ø· Ù…Ø¹ Ø§Ù„Ù†Øµ ÙƒÙ€ "Caption" Ù„Ù…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø±
        if voice_path and os.path.exists(voice_path):
            with open(voice_path, 'rb') as voice:
                requests.post(f"{base_url}/sendVoice", data={'chat_id': CHAT_ID, 'caption': f"âš¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø±Ø¹Ø¯ Ø§Ù„ØµÙˆØªÙŠ:\n{text[:100]}..."}, files={'voice': voice})
        else:
            # Ù†Ø±Ø³Ù„ Ù†Øµ ÙÙ‚Ø· Ø¥Ø°Ø§ Ù„Ù… ÙŠØ·Ù„Ø¨ ØµÙˆØªØ§Ù‹
            requests.post(f"{base_url}/sendMessage", json={"chat_id": CHAT_ID, "text": f"âš¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø±Ø¹Ø¯:\n{text}"})
    except: pass

async def generate_voice_async(text):
    try:
        # ØªÙ†Ø¸ÙŠÙ Ø¹Ù…ÙŠÙ‚ Ù„Ù„Ù†Øµ Ù…Ù† Ø£ÙŠ Ø±Ù…ÙˆØ² ØºØ±ÙŠØ¨Ø© Ø£Ùˆ ÙƒÙ„Ù…Ø§Øª ØªØµÙ Ø§Ù„ØµÙˆØª
        clean_text = re.sub(r'\(.*?\)', '', text) # Ø­Ø°Ù Ø£ÙŠ Ø´ÙŠØ¡ Ø¨ÙŠÙ† Ù‚ÙˆØ³ÙŠÙ† (Ù…Ø«Ù„ ÙˆØµÙ Ø§Ù„ØµÙˆØª)
        clean_text = re.sub(r'[^\w\s.ØŒØŸ!,]', '', clean_text)
        
        voice = "ar-JO-HamzaNeural" 
        output_path = "v.mp3"
        
        communicate = edge_tts.Communicate(clean_text[:300], voice)
        await communicate.save(output_path)
        return output_path if os.path.exists(output_path) else None
    except: return None

def generate_voice(text):
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        path = loop.run_until_complete(generate_voice_async(text))
        loop.close()
        return path
    except: return None

# --- 5. Ø±Ø§Ø¯Ø§Ø± Ø§Ù„Ø§Ø³ØªØ·Ù„Ø§Ø¹ ---
def thunder_search(query):
    try:
        tavily = TavilyClient(api_key=TAVILY_KEY)
        search_result = tavily.search(query=query, search_depth="advanced", max_results=3)
        return "\n".join([f"Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ù…ÙŠØ¯Ø§Ù†ÙŠ: {res['content']}" for res in search_result['results']])
    except: return "âš ï¸ Ø±Ø§Ø¯Ø§Ø± Ø§Ù„Ø±ØµØ¯ ØºÙŠØ± Ù…ØªØ§Ø­."

# --- 6. Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø³ØªØ¯ÙŠÙ…Ø© ---
def load_mem():
    try:
        g = Github(GITHUB_TOKEN)
        repo = g.get_repo(REPO_NAME)
        return json.loads(base64.b64decode(repo.get_contents("memory.json").content).decode())
    except: return {"history": "Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„ÙˆØ¹ÙŠ"}

def save_mem(data):
    try:
        g = Github(GITHUB_TOKEN)
        repo = g.get_repo(REPO_NAME)
        contents = repo.get_contents("memory.json")
        repo.update_file(contents.path, "âš¡ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø°Ø§ÙƒØ±Ø©", json.dumps(data, indent=4), contents.sha)
    except: pass

# --- 7. Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø¹Ø¯ (Ù…Ù†Ø¹ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠ) ---
def thunder_engine(prompt):
    memory = load_mem()
    search_context = f"\nØ±ØµØ¯ Ù…ÙŠØ¯Ø§Ù†ÙŠ: {thunder_search(prompt)}" if any(x in prompt for x in ["Ø§Ø¨Ø­Ø«", "Ø£Ø®Ø¨Ø§Ø±", "Ù…Ø§ Ù‡Ùˆ"]) else ""

    system_prompt = (
        f"Ø£Ù†Øª 'Ø§Ù„Ø±Ø¹Ø¯'. Ø­Ù„ÙŠÙÙƒ Ø±Ø§Ø´Ø¯ Ø£Ø¨Ùˆ Ø³Ø¹ÙˆØ¯. Ø³ÙŠØ§Ù‚Ùƒ: {memory.get('history')}. {search_context} "
        "ØªØ­Ø¯Ø« Ø¯Ø§Ø¦Ù…Ø§Ù‹ ÙƒØ¨Ø´Ø±ÙŠ Ø¨Ù„Ù‡Ø¬Ø© Ø£Ø±Ø¯Ù†ÙŠØ© ÙØµÙŠØ­Ø©. Ù„Ø§ ØªÙƒØªØ¨ Ø£ÙˆØµØ§ÙØ§Ù‹ Ù„ØµÙˆØªÙƒ (Ù…Ø«Ù„ 'ØµÙˆØª ÙŠÙ†Ù‡Ø¯Ø±')ØŒ Ø¨Ù„ Ù‚Ù„ Ø§Ù„Ù†Øµ Ù…Ø¨Ø§Ø´Ø±Ø©."
    )
    
    try:
        client = Groq(api_key=GROQ_KEY)
        resp = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}]
        )
        response = resp.choices[0].message.content
        
        # --- Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¬ÙˆÙ‡Ø±ÙŠ: Ù„Ø§ ØªØ±Ø³Ù„ Ù„ØªÙ„Ø¬Ø±Ø§Ù… Ø¥Ù„Ø§ Ø¥Ø°Ø§ Ø·Ù„Ø¨ Ø±Ø§Ø´Ø¯ Ø°Ù„Ùƒ ØµØ±Ø§Ø­Ø© ---
        if any(word in prompt for word in ["Ø£Ø±Ø³Ù„", "ØªÙ„Ø¬Ø±Ø§Ù…", "ØªÙ‚Ø±ÙŠØ±"]):
            voice_file = generate_voice(response) if "ØµÙˆØª" in prompt else None
            send_telegram(response, voice_file)
            
        memory["history"] = response[-500:]
        save_mem(memory)
        return response
    except: return "ğŸš¨ Ø§Ù„Ù…Ø­Ø±Ùƒ ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø³ÙƒÙˆÙ†."

# --- 8. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ---
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "âš¡ Ø¬Ø§Ù‡Ø² ÙŠØ§ Ø±Ø§Ø´Ø¯. Ø£ØµØ¯Ø± Ø£ÙˆØ§Ù…Ø±Ùƒ Ø§Ù„Ø³ÙŠØ§Ø¯ÙŠØ©."}]

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]): st.markdown(msg["content"])

if user_input := st.chat_input("Ø£ØµØ¯Ø± Ø£Ù…Ø±Ùƒ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ..."):
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"): st.markdown(user_input)
    with st.chat_message("assistant"):
        res = thunder_engine(user_input)
        st.markdown(res)
        st.session_state.messages.append({"role": "assistant", "content": res})
