import streamlit as st
import google.generativeai as genai
from duckduckgo_search import DDGS
from datetime import datetime

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="Jo Ai - Ø§Ù„Ù†Ø³Ø®Ø© 2.0 Ø§Ù„Ø£Ø­Ø¯Ø«", page_icon="ğŸš€", layout="centered")

# ØªØµÙ…ÙŠÙ… Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù†ÙŠÙ‚
st.markdown("""
<style>
    * { direction: rtl; text-align: right; }
    .stApp { background: linear-gradient(135deg, #0f0c29 0%, #302b63 50%, #24243e 100%); min-height: 100vh; }
    .stChatMessage { border-radius: 15px; margin-bottom: 15px; background: rgba(255, 255, 255, 0.1); color: white; }
</style>
""", unsafe_allow_html=True)

st.markdown('<div style="text-align:center; color:white;"><h1>ğŸš€ Ø¬Ùˆ Ø¢ÙŠ - Gemini 2.0</h1><p>Ø£Ù†Øª Ø§Ù„Ø¢Ù† ØªØ³ØªØ®Ø¯Ù… Ø£Ø³Ø±Ø¹ ÙˆØ£Ø­Ø¯Ø« Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…Ù† Ù‚ÙˆÙ‚Ù„</p></div>', unsafe_allow_html=True)

# 2. Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø­Ø±Ùƒ Gemini 2.0 Flash
if "GOOGLE_API_KEY" in st.secrets:
    try:
        genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
        # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù†Ø³Ø®Ø© 2.0 Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ø§Ù„Ø£Ø­Ø¯Ø«
        model = genai.GenerativeModel('gemini-2.0-flash-exp')
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¬Ø¯ÙŠØ¯: {str(e)}")
else:
    st.warning("âš ï¸ Ø¶ÙŠÙ Ø§Ù„Ù…ÙØªØ§Ø­ ÙÙŠ Secrets")

# 3. Ø§Ù„Ø³Ø¬Ù„ ÙˆØ§Ù„Ø¯Ø±Ø¯Ø´Ø©
if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

user_input = st.chat_input("Ø³ÙˆÙ„Ù Ù…Ø¹ Gemini 2.0 ÙŠØ§ Ù†Ø´Ù…ÙŠ...")

if user_input:
    with st.chat_message("user"):
        st.markdown(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    with st.spinner("â³ Ø§Ù„Ù†Ø³Ø®Ø© 2.0 Ø¹Ù… Ø¨ØªÙÙƒØ± Ø¨Ø°ÙƒØ§Ø¡..."):
        try:
            # Ø¨Ø­Ø« Ø³Ø±ÙŠØ¹ Ù„Ø¯Ø¹Ù… Ø§Ù„Ø±Ø¯
            search_context = ""
            try:
                with DDGS() as ddgs:
                    search_context = str([r for r in ddgs.text(user_input, max_results=2)])
            except:
                pass

            prompt = f"Ø£Ù†Øª Jo Ai Ø§Ù„Ø¥ØµØ¯Ø§Ø± 2.0. Ø±Ø¯ Ø¨Ù„Ù‡Ø¬Ø© Ø£Ø±Ø¯Ù†ÙŠØ© Ø°ÙƒÙŠØ© Ø¬Ø¯Ø§Ù‹ ÙˆÙ…Ø®ØªØµØ±Ø© Ø¹Ù„Ù‰: {user_input}. Ù…Ø¹Ù„ÙˆÙ…Ø§Øª: {search_context}"
            response = model.generate_content(prompt)
            
            with st.chat_message("assistant"):
                st.markdown(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
            
        except Exception as e:
            st.error("âš ï¸ Ø§Ù„Ù†Ø³Ø®Ø© 2.0 Ø¬Ø¯ÙŠØ¯Ø© Ø¬Ø¯Ø§Ù‹ØŒ Ø¥Ø°Ø§ Ù…Ø§ Ø±Ø¯Øª Ø§Ù†ØªØ¸Ø± Ø«ÙˆØ§Ù†ÙŠ ÙˆØ¬Ø±Ø¨ Ù…Ø±Ø© Ø«Ø§Ù†ÙŠØ©.")
