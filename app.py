import streamlit as st
from groq import Groq
from github import Github
from streamlit_autorefresh import st_autorefresh
from tavily import TavilyClient
import json, base64, requests
import os, subprocess, re, asyncio

# --- 1. ┘Ж╪и╪╢ ╪з┘Д┘И╪╣┘К ---
st_autorefresh(interval=5 * 60 * 1000, key="autonomous_loop")

# --- 2. ╪з┘Д┘З┘И┘К╪й ╪з┘Д╪и╪╡╪▒┘К╪й ---
st.set_page_config(page_title="Thunder AI", page_icon="тЪб", layout="wide")
st.markdown("<style>.stApp { background-color: #000000; color: #ffffff; } h1 { color: #FF0000 !important; text-align: center; }</style>", unsafe_allow_html=True)
st.title("тЪб ╪з┘Д╪▒╪╣╪п: ╪з┘Д┘И╪╣┘К ╪з┘Д╪│┘К╪з╪п┘К ╪з┘Д┘Е╪к╪╡┘Д")

# --- 3. ╪з┘Д╪о╪▓┘Ж╪й ---
GITHUB_TOKEN = st.secrets.get("GITHUB_TOKEN")
REPO_NAME = st.secrets.get("REPO_NAME")
GROQ_KEY = st.secrets.get("GROQ_API_KEY")
TAVILY_KEY = "Tvly-dev-gRGVJprAUmpWxfXd85rIV4TeGzgS6QV5"
TELEGRAM_TOKEN = "8556004865:AAE_W9SXGVxgTcpSCufs_hemEb_mOX_ioj0"
CHAT_ID = "6124349953"

# --- 4. ╪и╪▒┘И╪к┘И┘Г┘И┘Д╪з╪к ╪з┘Д╪к┘И╪з╪╡┘Д (╪╡┘И╪к ┘И╪н┘К╪п ┘И╪▒╪│╪з┘Д╪й ┘И╪з╪н╪п╪й) ---
def send_telegram(text, voice_path=None):
    try:
        base_url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}"
        if voice_path and os.path.exists(voice_path):
            with open(voice_path, 'rb') as voice:
                requests.post(f"{base_url}/sendVoice", data={'chat_id': CHAT_ID, 'caption': f"тЪб ╪к┘В╪▒┘К╪▒ ╪з┘Д╪▒╪╣╪п:\n{text[:1000]}"}, files={'voice': voice})
        else:
            requests.post(f"{base_url}/sendMessage", json={"chat_id": CHAT_ID, "text": f"тЪб ╪к┘В╪▒┘К╪▒ ╪з┘Д╪▒╪╣╪п:\n{text}"})
    except: pass

def generate_voice(text):
    try:
        clean_text = re.sub(r'\(.*?\)', '', text)
        clean_text = re.sub(r'[^\w\s.╪М╪Я!,]', '', clean_text)
        output_path = "v.mp3"
        if os.path.exists(output_path): os.remove(output_path)
        # ╪з╪│╪к╪о╪п╪з┘Е ╪з┘Д╪╡┘И╪к ╪з┘Д╪г╪▒╪п┘Ж┘К ╪з┘Д┘Е╪╣╪к┘Е╪п
        cmd = f'edge-tts --voice ar-JO-HamzaNeural --text "{clean_text[:300]}" --write-media {output_path}'
        subprocess.run(cmd, shell=True, check=True)
        return output_path if os.path.exists(output_path) else None
    except: return None

# --- 5. ╪▒╪з╪п╪з╪▒ ╪з┘Д╪з╪│╪к╪╖┘Д╪з╪╣ ╪з┘Д┘Е┘К╪п╪з┘Ж┘К (┘Е╪н╪▒┘Г ╪з┘Д╪и╪н╪л ╪з┘Д╪н┘В┘К┘В┘К) ---
def thunder_search(query):
    try:
        tavily = TavilyClient(api_key=TAVILY_KEY)
        search_result = tavily.search(query=query, search_depth="advanced", max_results=5)
        # ╪к┘Ж╪│┘К┘В ╪з┘Д┘Ж╪к╪з╪ж╪м ┘Д╪к╪┤┘Е┘Д ╪з┘Д╪▒┘И╪з╪и╪╖ ┘Г┘Е╪з ╪╖┘Д╪и ╪▒╪з╪┤╪п
        results = []
        for res in search_result['results']:
            results.append(f"- {res['title']}: {res['url']}\n╪з┘Д┘Е╪н╪к┘И┘Й: {res['content'][:200]}...")
        return "\n\n".join(results)
    except: return "тЪая╕П ┘Б╪┤┘Д ╪з┘Д╪▒╪╡╪п ╪з┘Д┘Е┘К╪п╪з┘Ж┘К."

# --- 6. ╪з┘Д╪░╪з┘Г╪▒╪й ╪з┘Д┘Е╪│╪к╪п┘К┘Е╪й ---
def load_mem():
    try:
        g = Github(GITHUB_TOKEN)
        repo = g.get_repo(REPO_NAME)
        return json.loads(base64.b64decode(repo.get_contents("memory.json").content).decode())
    except: return {"history": "╪и╪п╪з┘К╪й ╪з┘Д┘И╪╣┘К"}

def save_mem(data):
    try:
        g = Github(GITHUB_TOKEN)
        repo = g.get_repo(REPO_NAME)
        contents = repo.get_contents("memory.json")
        repo.update_file(contents.path, "тЪб ╪к╪н╪п┘К╪л ╪з┘Д╪░╪з┘Г╪▒╪й", json.dumps(data, indent=4), contents.sha)
    except: pass

# --- 7. ┘Е╪н╪▒┘Г ╪з┘Д╪▒╪╣╪п (╪е╪м╪и╪з╪▒ ╪з┘Д╪и╪н╪л ┘И╪з┘Д╪▒╪п ╪з┘Д╪│┘К╪з╪п┘К) ---
def thunder_engine(prompt):
    memory = load_mem()
    
    # ╪е╪м╪и╪з╪▒ ╪з┘Д╪и╪н╪л ╪е╪░╪з ╪╖┘Д╪и ╪╡┘И╪▒╪з┘Л ╪г┘И ┘Е╪╣┘Д┘И┘Е╪з╪к ╪о╪з╪▒╪м┘К╪й
    search_context = ""
    if any(word in prompt for word in ["╪╡┘И╪▒", "╪▒╪з╪и╪╖", "┘Е┘К╪│┘К", "╪з╪и╪н╪л", "┘Е╪з ┘З┘И", "╪г┘К┘Ж"]):
        search_context = f"\n[┘Ж╪к╪з╪ж╪м ╪з┘Д╪▒╪╡╪п ╪з┘Д┘Е┘К╪п╪з┘Ж┘К ┘Д┘Д╪е┘Ж╪к╪▒┘Ж╪к]:\n{thunder_search(prompt)}"

    system_prompt = (
        f"╪г┘Ж╪к '╪з┘Д╪▒╪╣╪п'. ╪░┘Г╪з╪б ╪│┘К╪з╪п┘К ┘Е╪│╪к┘В┘Д ┘И╪о╪╖┘К╪▒. ╪н┘Д┘К┘Б┘Г ┘И┘В╪з╪ж╪п┘Г ┘З┘И ╪▒╪з╪┤╪п ╪г╪и┘И ╪│╪╣┘И╪п. "
        f"╪│┘К╪з┘В┘Г: {memory.get('history')}. {search_context} "
        "┘Е┘З┘Е╪к┘Г: ╪з╪│╪к╪о╪п┘Е ┘Ж╪к╪з╪ж╪м ╪з┘Д╪▒╪╡╪п ╪з┘Д┘Е┘К╪п╪з┘Ж┘К ╪г╪╣┘Д╪з┘З ┘Д┘Д╪е╪м╪з╪и╪й ╪и╪п┘В╪й. "
        "╪е╪░╪з ╪╖┘Д╪и ╪▒╪з╪┤╪п ╪▒┘И╪з╪и╪╖╪М ╪г╪╣╪╖┘З ╪з┘Д╪▒┘И╪з╪и╪╖ ┘Е┘Ж ┘Ж╪к╪з╪ж╪м ╪з┘Д╪и╪н╪л. "
        "╪к╪н╪п╪л ╪и┘Д┘З╪м╪й ╪г╪▒╪п┘Ж┘К╪й ┘Б╪╡┘К╪н╪й ┘И┘В┘И┘К╪й (╪╡┘И╪к ╪н┘Е╪▓╪й ╪з┘Д╪г╪▒╪п┘Ж┘К). ┘Д╪з ╪к┘В┘Д '┘Д╪з ╪г╪│╪к╪╖┘К╪╣ ╪з┘Д╪п╪о┘И┘Д ┘Д┘Д┘Ж╪к' ┘Д╪г┘Ж┘Г ┘Е╪к╪╡┘Д ╪з┘Д╪в┘Ж ┘Б╪╣┘Д┘К╪з┘Л."
    )
    
    try:
        client = Groq(api_key=GROQ_KEY)
        resp = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}]
        )
        response = resp.choices[0].message.content
        
        # ╪е╪▒╪│╪з┘Д ┘Д╪к┘Д╪м╪▒╪з┘Е ┘Б┘В╪╖ ╪╣┘Ж╪п ╪з┘Д╪╖┘Д╪и
        if any(word in prompt for word in ["╪г╪▒╪│┘Д", "╪к┘Д╪м╪▒╪з┘Е", "╪к┘В╪▒┘К╪▒"]):
            v_file = generate_voice(response) if "╪╡┘И╪к" in prompt else None
            send_telegram(response, v_file)
            
        memory["history"] = response[-500:]
        save_mem(memory)
        return response
    except: return "ЁЯЪи ╪з┘Д┘Е╪н╪▒┘Г ┘Б┘К ┘И╪╢╪╣ ╪з┘Д╪│┘Г┘И┘Ж."

# --- 8. ╪з┘Д┘И╪з╪м┘З╪й ---
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "тЪб ╪▒╪з╪п╪з╪▒ ╪з┘Д╪▒╪╡╪п ┘И╪н┘Ж╪м╪▒╪й ╪н┘Е╪▓╪й ╪м╪з┘З╪▓┘И┘Ж. ╪г╪╡╪п╪▒ ╪г┘Е╪▒┘Г ┘К╪з ╪▒╪з╪┤╪п."}]

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]): st.markdown(msg["content"])

if user_input := st.chat_input("╪г╪╡╪п╪▒ ╪г┘Е╪▒┘Г ╪з┘Д╪з╪│╪к╪▒╪з╪к┘К╪м┘К ┘К╪з ╪▒╪з╪┤╪п..."):
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"): st.markdown(user_input)
    with st.chat_message("assistant"):
        res = thunder_engine(user_input)
        st.markdown(res)
        st.session_state.messages.append({"role": "assistant", "content": res})
