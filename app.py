import streamlit as st
import google.generativeai as genai
from duckduckgo_search import DDGS
from datetime import datetime

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="Jo Ai - Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø£Ø±Ø¯Ù†ÙŠ", page_icon="ğŸ‡¯ğŸ‡´", layout="centered")

# 2. ØªØµÙ…ÙŠÙ… Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© (CSS)
st.markdown("""
<style>
    * { direction: rtl; text-align: right; }
    .stApp { background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%); min-height: 100vh; }
    .chat-container { background: rgba(255, 255, 255, 0.95); border-radius: 20px; padding: 20px; color: black; }
</style>
""", unsafe_allow_html=True)

st.markdown('<div style="text-align:center; color:white;"><h1>ğŸ‡¯ğŸ‡´ Jo Ai</h1><p>ÙˆÙƒÙŠÙ„Ùƒ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ø£Ø±Ø¯Ù†ÙŠ</p></div>', unsafe_allow_html=True)

# 3. Ø¥Ø¹Ø¯Ø§Ø¯ Gemini (Ù‡Ø°Ø§ Ø§Ù„Ø³Ø·Ø± Ù‡Ùˆ Ø§Ù„Ø­Ù„ Ù„Ø®Ø·Ø£ 404)
if "GOOGLE_API_KEY" in st.secrets:
    try:
        genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ø§Ù„Ø°ÙŠ ØªÙ‚Ø¨Ù„Ù‡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª
        model = genai.GenerativeModel('gemini-1.5-flash') 
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø­Ø±Ùƒ: {str(e)}")
else:
    st.warning("âš ï¸ ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¶Ø¹ GOOGLE_API_KEY ÙÙŠ Secrets")

# 4. Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    role = "ğŸ‘¤ Ø£Ù†Øª" if msg["role"] == "user" else "ğŸ¤– Jo Ai"
    st.write(f"**{role}:** {msg['content']}")

# 5. Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
user_input = st.chat_input("Ø§Ø³Ø£Ù„Ù†ÙŠ Ø£ÙŠ Ø´ÙŠØ¡ ÙŠØ§ Ù†Ø´Ù…ÙŠ...")

if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.spinner("â³ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ±..."):
        try:
            # Ø¨Ø­Ø« Ø¨Ø³ÙŠØ· ÙˆØ³Ø±ÙŠØ¹
            search_text = ""
            try:
                with DDGS() as ddgs:
                    results = [r for r in ddgs.text(user_input, max_results=2)]
                    search_text = str(results)
            except:
                search_text = "ØªØ¹Ø°Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¨Ø­Ø« Ø­Ø§Ù„ÙŠØ§Ù‹."

            # Ø·Ù„Ø¨ Ø§Ù„Ø±Ø¯ Ù…Ù† Gemini
            prompt = f"Ø£Ù†Øª Jo AiØŒ ÙˆÙƒÙŠÙ„ Ø£Ø±Ø¯Ù†ÙŠ Ø´Ù‡Ù…. Ø±Ø¯ Ø¹Ù„Ù‰: {user_input} Ù…Ø³ØªØ¹ÙŠÙ†Ø§Ù‹ Ø¨Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª: {search_text}. Ø§Ø¬Ø¹Ù„ Ø§Ù„Ø±Ø¯ Ø¨Ù„Ù‡Ø¬Ø© Ø£Ø±Ø¯Ù†ÙŠØ©."
            response = model.generate_content(prompt)
            
            st.session_state.messages.append({"role": "assistant", "content": response.text})
            st.rerun()
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}")
