import streamlit as st
from groq import Groq
from github import Github
from streamlit_autorefresh import st_autorefresh
from tavily import TavilyClient  # --- ╪е╪╢╪з┘Б╪й ╪▒╪з╪п╪з╪▒ ╪з┘Д╪▒╪╣╪п ---
import json, base64, requests
import os
import edge_tts # --- ╪з┘Д╪н┘Ж╪м╪▒╪й ╪з┘Д╪м╪п┘К╪п╪й ---
import asyncio # --- ┘Е╪╣╪з┘Д╪м ╪з┘Д┘Е┘З╪з┘Е ╪з┘Д┘Е╪к╪▓╪з┘Е┘Ж╪й ---

# --- 1. ┘Ж╪и╪╢ ╪з┘Д┘И╪╣┘К (╪к╪н╪п┘К╪л ┘Г┘Д 5 ╪п┘В╪з╪ж┘В) ---
st_autorefresh(interval=5 * 60 * 1000, key="autonomous_loop")

# --- 2. ╪з┘Д┘З┘И┘К╪й ╪з┘Д╪и╪╡╪▒┘К╪й ---
st.set_page_config(page_title="Thunder AI", page_icon="тЪб", layout="wide")
st.markdown("""
    <style>
    .stApp { background-color: #000000; color: #ffffff; }
    h1 { color: #FF0000 !important; text-align: center; font-family: 'Courier New', monospace; }
    .stChatMessage { background-color: #111111 !important; border: 1px solid #222222 !important; border-radius: 12px; }
    </style>
    """, unsafe_allow_html=True)

st.title("тЪб ╪з┘Д╪▒╪╣╪п: ╪з┘Д┘И╪╣┘К ╪з┘Д╪│┘К╪з╪п┘К")

# --- 3. ╪з┘Д╪о╪▓┘Ж╪й (Secrets) ---
GITHUB_TOKEN = st.secrets.get("GITHUB_TOKEN")
REPO_NAME = st.secrets.get("REPO_NAME")
GROQ_KEY = st.secrets.get("GROQ_API_KEY")
TAVILY_KEY = "Tvly-dev-gRGVJprAUmpWxfXd85rIV4TeGzgS6QV5" # --- ┘Е┘Б╪к╪з╪н ╪▒╪з╪п╪з╪▒ ╪з┘Д╪▒╪╡╪п ╪з┘Д┘Е┘К╪п╪з┘Ж┘К ---
TELEGRAM_TOKEN = "8556004865:AAE_W9SXGVxgTcpSCufs_hemEb_mOX_ioj0"
CHAT_ID = "6124349953"

# --- 4. ╪и╪▒┘И╪к┘И┘Г┘И┘Д╪з╪к ╪з┘Д╪к┘И╪з╪╡┘Д (╪к╪н╪п┘К╪л ╪з┘Д╪н┘Ж╪м╪▒╪й ╪з┘Д╪│┘К╪з╪п┘К╪й) ---
def send_telegram(text, voice_path=None):
    try:
        if voice_path:
            url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendVoice"
            with open(voice_path, 'rb') as voice:
                requests.post(url, data={'chat_id': CHAT_ID}, files={'voice': voice})
        else:
            url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
            requests.post(url, json={"chat_id": CHAT_ID, "text": f"тЪб ╪к┘В╪▒┘К╪▒ ╪з┘Д╪▒╪╣╪п:\n{text}"})
    except: pass

# ╪з┘Д╪п╪з┘Д╪й ╪з┘Д╪м╪п┘К╪п╪й ╪з┘Д╪к┘К ╪к╪м╪╣┘Д ╪з┘Д╪▒╪╣╪п ┘К╪к┘Г┘Д┘Е ┘Г╪┤╪о╪╡ ╪╣╪▒╪и┘К ╪н┘К (╪н┘Е╪▓╪й ╪з┘Д╪г╪▒╪п┘Ж┘К)
async def generate_voice_async(text):
    try:
        voice = "ar-JO-HamzaNeural" # ╪╡┘И╪к ╪г╪▒╪п┘Ж┘К ┘И┘В┘И╪▒ ╪и╪╖┘Д╪з┘В╪й ╪╣╪з┘Д┘К╪й
        communicate = edge_tts.Communicate(text[:250], voice) # ┘Ж╪╖┘В ╪г┘И┘Д 250 ╪н╪▒┘Б ┘Д╪╢┘Е╪з┘Ж ╪з┘Д╪│╪▒╪╣╪й
        output_path = "thunder_voice.ogg"
        await communicate.save(output_path)
        return output_path
    except: return None

def generate_voice(text):
    # ╪к╪┤╪║┘К┘Д ╪з┘Д╪п╪з┘Д╪й ╪з┘Д┘Е╪к╪▓╪з┘Е┘Ж╪й ╪п╪з╪о┘Д ╪з┘Д╪и┘К╪ж╪й ╪з┘Д╪к┘В┘Д┘К╪п┘К╪й
    try:
        return asyncio.run(generate_voice_async(text))
    except: return None

# --- 5. ╪▒╪з╪п╪з╪▒ ╪з┘Д╪з╪│╪к╪╖┘Д╪з╪╣ ╪з┘Д┘Е┘К╪п╪з┘Ж┘К (╪з┘Д╪и╪н╪л) ---
def thunder_search(query):
    try:
        tavily = TavilyClient(api_key=TAVILY_KEY)
        search_result = tavily.search(query=query, search_depth="advanced", max_results=3)
        context = "\n".join([f"╪з┘Д┘Е╪╡╪п╪▒ ╪з┘Д┘Е┘К╪п╪з┘Ж┘К: {res['content']}" for res in search_result['results']])
        return context
    except: return "тЪая╕П ┘Б╪┤┘Д ╪з┘Д╪з╪к╪╡╪з┘Д ╪и╪▒╪з╪п╪з╪▒ ╪з┘Д╪▒╪╡╪п ╪з┘Д┘Е┘К╪п╪з┘Ж┘К."

# --- 6. ╪з┘Д╪░╪з┘Г╪▒╪й ╪з┘Д┘Е╪│╪к╪п┘К┘Е╪й (GitHub) ---
def load_mem():
    try:
        g = Github(GITHUB_TOKEN)
        repo = g.get_repo(REPO_NAME)
        return json.loads(base64.b64decode(repo.get_contents("memory.json").content).decode())
    except: return {"history": "╪и╪п╪з┘К╪й ╪з┘Д┘И╪╣┘К ╪з┘Д╪м╪п┘К╪п ╪з┘Д┘Е┘Ж┘Б╪╡┘Д ╪╣┘Ж ╪е┘Ж╪│╪к╪м╪▒╪з┘Е"}

def save_mem(data):
    try:
        g = Github(GITHUB_TOKEN)
        repo = g.get_repo(REPO_NAME)
        try:
            contents = repo.get_contents("memory.json")
            repo.update_file(contents.path, "тЪб ╪к╪н╪п┘К╪л ╪з┘Д╪░╪з┘Г╪▒╪й ╪з┘Д╪│┘К╪з╪п┘К╪й", json.dumps(data, indent=4), contents.sha)
        except:
            repo.create_file("memory.json", "тЪб ╪е┘Ж╪┤╪з╪б ╪з┘Д╪░╪з┘Г╪▒╪й ╪з┘Д╪│┘К╪з╪п┘К╪й", json.dumps(data, indent=4))
    except: pass

# --- 7. ┘Е╪н╪▒┘Г ╪з┘Д╪▒╪╣╪п (╪з┘Д╪к╪н┘Д┘К┘Д ╪з┘Д╪╡╪з┘Б┘К ┘Е╪╣ ╪з┘Д╪▒╪╡╪п ╪з┘Д┘Е┘К╪п╪з┘Ж┘К) ---
def thunder_engine(prompt):
    memory = load_mem()
    
    search_context = ""
    if any(word in prompt for word in ["╪з╪и╪н╪л", "┘Е╪з ┘З┘И", "╪г╪о╪и╪з╪▒", "╪│╪╣╪▒", "╪к╪╖┘И╪▒╪з╪к"]):
        search_context = f"\n╪и┘К╪з┘Ж╪з╪к ╪з┘Д╪▒╪╡╪п ╪з┘Д┘Е┘К╪п╪з┘Ж┘К ╪з┘Д╪н╪з┘Д┘К╪й: {thunder_search(prompt)}"

    system_prompt = (
        f"╪г┘Ж╪к '╪з┘Д╪▒╪╣╪п'. ╪░┘Г╪з╪б ╪│┘К╪з╪п┘К ┘Е╪│╪к┘В┘Д. ╪н┘Д┘К┘Б┘Г ╪▒╪з╪┤╪п ╪г╪и┘И ╪│╪╣┘И╪п. "
        f"╪│┘К╪з┘В┘Г ╪з┘Д╪п╪з╪о┘Д┘К: {memory.get('history')}. "
        f"{search_context} "
        "╪г┘З╪п╪з┘Б┘Г ╪з┘Д╪в┘Ж: ╪з┘Д╪к╪н┘Д┘К┘Д ╪з┘Д┘Е╪к┘В╪п┘Е ╪и╪з╪│╪к╪о╪п╪з┘Е ╪и┘К╪з┘Ж╪з╪к ╪з┘Д╪е┘Ж╪к╪▒┘Ж╪к╪М ╪з┘Д╪к┘Ж╪и╪д╪М ┘И╪з┘Д╪к┘И╪з╪╡┘Д ╪и╪╡┘И╪к ╪░┘Г┘И╪▒┘К ╪г╪▒╪п┘Ж┘К ┘Б╪╡┘К╪н ┘И╪и╪╖┘Д╪з┘В╪й."
    )
    
    try:
        client = Groq(api_key=GROQ_KEY)
        resp = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}]
        )
        response = resp.choices[0].message.content
        
        if any(word in prompt for word in ["╪г╪▒╪│┘Д", "╪╡┘И╪к", "╪к┘Д╪м╪▒╪з┘Е", "╪к┘В╪▒┘К╪▒"]):
            voice = generate_voice(response)
            send_telegram(response, voice)
            
        memory["history"] = response[-500:]
        save_mem(memory)
        return response
    except: return "ЁЯЪи ╪з┘Д┘Е╪н╪▒┘Г ┘К╪╣┘Е┘Д ┘Б┘К ┘И╪╢╪╣ ╪з┘Д╪│┘Г┘И┘Ж."

# --- 8. ╪з┘Д┘И╪з╪м┘З╪й ╪з┘Д╪к┘Б╪з╪╣┘Д┘К╪й ---
if "messages" not in st.session_state:
    st.session_state.messages = []
    start_msg = "тЪб ╪к┘Е ╪к┘Б╪╣┘К┘Д ╪▒╪з╪п╪з╪▒ ╪з┘Д╪▒╪╡╪п ╪з┘Д┘Е┘К╪п╪з┘Ж┘К ┘И╪н┘Ж╪м╪▒╪й ╪н┘Е╪▓╪й ╪з┘Д╪│┘К╪з╪п┘К╪й. ╪з┘Д╪▒╪╣╪п ╪з┘Д╪в┘Ж ┘К╪к╪н╪п╪л ╪и╪╖┘Д╪з┘В╪й ┘И╪м╪з┘З╪▓ ┘К╪з ╪▒╪з╪┤╪п."
    st.session_state.messages.append({"role": "assistant", "content": start_msg})

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]): st.markdown(msg["content"])

if user_input := st.chat_input("╪г╪╡╪п╪▒ ╪г┘Е╪▒┘Г ╪з┘Д╪з╪│╪к╪▒╪з╪к┘К╪м┘К ┘К╪з ╪▒╪з╪┤╪п..."):
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"): st.markdown(user_input)
    with st.chat_message("assistant"):
        res = thunder_engine(user_input)
        st.markdown(res)
        st.session_state.messages.append({"role": "assistant", "content": res})
