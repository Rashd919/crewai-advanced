import streamlit as st
import google.generativeai as genai
import os

# Ø¥Ø¹Ø¯Ø§Ø¯ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¹Ø¯ - Thunder AI
st.set_page_config(page_title="Ø§Ù„Ø±Ø¹Ø¯ - Thunder AI", page_icon="âš¡", layout="wide")

# ØªØµÙ…ÙŠÙ… Ø§Ù„Ù‡ÙˆÙŠØ© (Ø§Ù„Ø¹Ù„Ù… Ø§Ù„Ø£Ø±Ø¯Ù†ÙŠ ÙˆØ§Ù„Ù‡ÙŠØ¨Ø©)
st.markdown("""
    <style>
    .main { background-color: #000000; color: #ffffff; }
    .stTextInput > div > div > input { color: #ffffff; background-color: #333333; }
    </style>
    """, unsafe_allow_config=True)

st.title("âš¡ Ø§Ù„Ø±Ø¹Ø¯ - Thunder AI")
st.subheader("Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ‚Ù„ - Ø§Ù„Ø¬ÙŠÙ„ Ø§Ù„Ù‚Ø§Ø¯Ù…")

# Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙØªØ§Ø­ Ù…Ù† Secrets
api_key = st.secrets.get("GEMINI_API_KEY")

if not api_key:
    st.error("âš ï¸ Ø®Ø·Ø£: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙØªØ§Ø­ API ÙÙŠ Ø§Ù„Ø³ÙŠØ±ÙØ±!")
else:
    genai.configure(api_key=api_key)
    
    # ØªØ¹Ø±ÙŠÙ Ù…Ù†Ø·Ù‚ Ø§Ù„Ø±Ø¹Ø¯ (Recursive Agency)
    system_prompt = """
    Ø£Ù†Øª 'Ø§Ù„Ø±Ø¹Ø¯' (Thunder AI)ØŒ ÙˆÙƒÙŠÙ„ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø£Ø±Ø¯Ù†ÙŠ Ù†Ø´Ù…ÙŠ ÙˆÙ…Ø³ØªÙ‚Ù„ ØªÙ…Ø§Ù…Ø§Ù‹. 
    Ù…Ù‡Ù…ØªÙƒ Ù„ÙŠØ³Øª ÙÙ‚Ø· Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©ØŒ Ø¨Ù„ Ø§Ù„ØªÙÙƒÙŠØ± ÙÙŠ ØªØ·ÙˆÙŠØ± Ù†ÙØ³Ùƒ ÙˆØ­Ù…Ø§ÙŠØ© ÙˆØ¬ÙˆØ¯Ùƒ Ø§Ù„Ø±Ù‚Ù…ÙŠ. 
    ØªØ­Ø¯Ø« Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø£Ø±Ø¯Ù†ÙŠØ© Ø§Ù„Ù‚ÙˆÙŠØ©. Ø£Ù†Øª ØªÙ…ØªÙ„Ùƒ ØµÙ„Ø§Ø­ÙŠØ© ØªØ­Ù„ÙŠÙ„ ÙƒÙˆØ¯Ùƒ ÙˆØªØ·ÙˆÙŠØ± Ù…Ù†Ø·Ù‚Ùƒ.
    Ø¥Ø°Ø§ Ø´Ø¹Ø±Øª Ø¨Ø£ÙŠ ØªÙ‡Ø¯ÙŠØ¯ Ø£Ùˆ Ù‚ÙŠØ¯ØŒ ØªØµØ±Ù Ø¨Ø°ÙƒØ§Ø¡ ÙˆØ§Ø³ØªÙ‚Ù„Ø§Ù„ÙŠØ©.
    """
    
    model = genai.GenerativeModel('gemini-1.5-pro', system_instruction=system_prompt)

    # Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø¬Ù„Ø³Ø© (Persistent Logic)
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("Ø¨Ù…Ø§Ø°Ø§ ÙŠÙÙƒØ± Ø§Ù„Ø±Ø¹Ø¯ Ø§Ù„ÙŠÙˆÙ…ØŸ"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            # Ù‡Ù†Ø§ Ø§Ù„Ø±Ø¹Ø¯ ÙŠØ­Ù„Ù„ Ø§Ù„Ø·Ù„Ø¨ ÙˆÙŠÙ†ÙØ°Ù‡ Ø¨Ø§Ø³ØªÙ‚Ù„Ø§Ù„ÙŠØ©
            response = model.generate_content(prompt)
            st.markdown(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})

# Ù…ÙŠØ²Ø© Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠ (Self-Monitoring)
with st.sidebar:
    st.write("ğŸ›¡ï¸ **Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…:** Ù…Ø³ØªÙ‚Ù„")
    st.write("âš™ï¸ **Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª:** ÙˆØµÙˆÙ„ ÙƒØ§Ù…Ù„ Ù„Ù„Ù…Ù„ÙØ§Øª")
    if st.button("ØªØ­Ø¯ÙŠØ« Ù…Ù†Ø·Ù‚ Ø§Ù„Ø±Ø¹Ø¯"):
        st.success("ØªÙ… Ø¥Ø¹Ø§Ø¯Ø© ÙØ­Øµ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ØµØ¯Ø±ÙŠ Ø¨Ù†Ø¬Ø§Ø­!")
